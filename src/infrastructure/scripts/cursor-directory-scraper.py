#!/usr/bin/env python3
"""
@file: cursor-directory-scraper.py
@description: –°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ MCP —Å–µ—Ä–≤–µ—Ä–æ–≤ –Ω–∞ cursor.directory
@dependencies: playwright, requests, json, os, sys
@created: 2025-08-17
@updated: 2025-01-27 - –æ–±–Ω–æ–≤–ª–µ–Ω—ã —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π —Å–∞–π—Ç–∞
@pager-protection: –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç pager –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
"""

import asyncio
import json
import os
import sys
import subprocess
from typing import List, Dict, Optional
from pathlib import Path

def setup_pager_protection():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞—â–∏—Ç—ã –æ—Ç pager –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏"""
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è pager
    os.environ['PAGER'] = 'cat'
    os.environ['LESS'] = '-R -M --shift 5'
    os.environ['MORE'] = '-R'
    os.environ['COMPOSER_NO_INTERACTION'] = '1'
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º git pager –≥–ª–æ–±–∞–ª—å–Ω–æ
    try:
        subprocess.run(['git', 'config', '--global', 'core.pager', 'cat'], 
                      capture_output=True, check=True)
        print("‚úÖ –ó–∞—â–∏—Ç–∞ –æ—Ç pager –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
    except subprocess.CalledProcessError:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å git pager (git –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ pager: {e}")

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞—â–∏—Ç—ã –æ—Ç pager –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
setup_pager_protection()

try:
    from playwright.async_api import async_playwright
except ImportError:
    print("‚ùå Playwright –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install playwright")
    print("   –ó–∞—Ç–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: playwright install")
    sys.exit(1)

class CursorDirectoryScraper:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ MCP —Å–µ—Ä–≤–µ—Ä–æ–≤ –Ω–∞ cursor.directory"""
    
    def __init__(self, cache_dir: str = "mcp_cache"):
        self.base_url = "https://cursor.directory/mcp"
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
    async def search_mcp_servers(self, query: str) -> List[Dict]:
        """–ü–æ–∏—Å–∫ MCP —Å–µ—Ä–≤–µ—Ä–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        print(f"üîç –ü–æ–∏—Å–∫ MCP —Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_file = self.cache_dir / f"{query}.json"
        if cache_file.exists():
            print(f"üìÅ –ù–∞–π–¥–µ–Ω –∫—ç—à –¥–ª—è '{query}', –∑–∞–≥—Ä—É–∂–∞–µ–º...")
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
                search_url = f"{self.base_url}?q={query}"
                print(f"üåê –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞: {search_url}")
                
                await page.goto(search_url, wait_until='networkidle')
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
                
                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                await page.wait_for_load_state('domcontentloaded')
                
                # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ (–Ω–µ featured —Å–µ–∫—Ü–∏–∏)
                print("‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞...")
                await page.wait_for_timeout(3000)  # –î–∞–µ–º –≤—Ä–µ–º—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                
                # –ò—â–µ–º –æ–±–ª–∞—Å—Ç—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞ (–∏—Å–∫–ª—é—á–∞—è featured —Å–µ–∫—Ü–∏—é)
                # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –æ–±–ª–∞—Å—Ç—å –ø–æ—Å–ª–µ featured —Å–µ–∫—Ü–∏–∏
                search_results_area = None
                
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –æ–±–ª–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
                area_selectors = [
                    'main > div:not(:first-child)',  # –í—Å–µ div –≤ main –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ (featured)
                    '[class*="grid"]:not(:first-child)',  # Grid –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                    '[class*="results"]',  # –û–±–ª–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    '[class*="search"]',  # –û–±–ª–∞—Å—Ç—å –ø–æ–∏—Å–∫–∞
                    'section:not(:first-child)',  # –°–µ–∫—Ü–∏–∏ –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π (featured)
                    'div[class*="container"] > div:not(:first-child)'  # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                ]
                
                for selector in area_selectors:
                    try:
                        print(f"üîç –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –æ–±–ª–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                        elements = await page.query_selector_all(selector)
                        if elements:
                            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç (–æ–±—ã—á–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤–Ω–∏–∑—É)
                            search_results_area = elements[-1]
                            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ–±–ª–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            break
                    except Exception as e:
                        print(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
                        continue
                
                if not search_results_area:
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∏—â–µ–º –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏...")
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å, –∏—â–µ–º –≤—Å–µ –∫–∞—Ä—Ç–æ—á–∫–∏, –Ω–æ –∏—Å–∫–ª—é—á–∞–µ–º featured
                    search_results_area = page
                
                # –¢–µ–ø–µ—Ä—å –∏—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                card_selectors = [
                    '[data-testid="mcp-card"]',
                    '.mcp-card',
                    '[class*="card"]',
                    '[class*="mcp"]',
                    'article',
                    '.grid > div',
                    '[role="article"]',
                    'a[href*="/mcp/"]',  # –°—Å—ã–ª–∫–∏ –Ω–∞ MCP —Å–µ—Ä–≤–µ—Ä—ã
                    'div[class*="item"]',  # –≠–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞
                    'div[class*="server"]'  # –°–µ—Ä–≤–µ—Ä—ã
                ]
                
                cards = []
                used_selector = None
                
                for selector in card_selectors:
                    try:
                        print(f"üîç –ü—Ä–æ–±—É–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫: {selector}")
                        if search_results_area == page:
                            cards = await page.query_selector_all(selector)
                        else:
                            cards = await search_results_area.query_selector_all(selector)
                        
                        if cards:
                            # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏, –∏—Å–∫–ª—é—á–∞—è featured
                            filtered_cards = []
                            for card in cards:
                                try:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–∞—Ä—Ç–æ—á–∫–∞ featured
                                    card_text = await card.text_content()
                                    if card_text:
                                        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º featured —Å–µ—Ä–≤–µ—Ä–æ–≤
                                        featured_keywords = ['postman', 'byterover', 'bucket', 'allthingsdev']
                                        is_featured = any(keyword in card_text.lower() for keyword in featured_keywords)
                                        if not is_featured:
                                            filtered_cards.append(card)
                                except:
                                    filtered_cards.append(card)
                            
                            if filtered_cards:
                                cards = filtered_cards
                                used_selector = selector
                                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                                break
                    except Exception as e:
                        print(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
                        continue
                
                if not cards:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞")
                    print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
                    
                    # –ü–æ–ª—É—á–∞–µ–º HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    html_content = await page.content()
                    print(f"üìÑ –†–∞–∑–º–µ—Ä HTML: {len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    # –ò—â–µ–º –ª—é–±—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ MCP —Å–µ—Ä–≤–µ—Ä—ã
                    links = await page.query_selector_all('a[href*="mcp"]')
                    print(f"üîó –ù–∞–π–¥–µ–Ω–æ {len(links)} —Å—Å—ã–ª–æ–∫ —Å 'mcp' –≤ href")
                    
                    # –ò—â–µ–º –ª—é–±—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º "MCP"
                    mcp_elements = await page.query_selector_all('*:has-text("MCP")')
                    print(f"üìù –ù–∞–π–¥–µ–Ω–æ {len(mcp_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º 'MCP'")
                    
                    return []
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–µ—Ä–≤–µ—Ä–∞—Ö
                servers = await self._extract_servers_data(page, cards, used_selector)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(servers, f, ensure_ascii=False, indent=2)
                
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(servers)} —Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è '{query}'")
                return servers
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}")
                return []
            finally:
                await browser.close()
    
    async def _extract_servers_data(self, page, cards, selector: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Å–µ—Ä–≤–µ—Ä–∞—Ö —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        servers = []
        
        print(f"üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫...")
        
        for i, card in enumerate(cards):
            try:
                print(f"üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫—É {i+1}/{len(cards)}")
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
                title = await self._extract_text(card, [
                    '[data-testid="mcp-title"]',
                    '.title',
                    'h3',
                    'h2',
                    'h1',
                    '[class*="title"]',
                    'strong',
                    'b',
                    'a',  # –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Å—Å—ã–ª–∫–µ
                    '[class*="name"]'
                ])
                
                description = await self._extract_text(card, [
                    '[data-testid="mcp-description"]',
                    '.description',
                    'p',
                    '[class*="desc"]',
                    '[class*="summary"]',
                    '[class*="text"]',
                    'span'
                ])
                
                # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫
                link = await self._extract_link(card)
                
                icon = await self._extract_attribute(card, 'img', 'src', [
                    'img',
                    '[src]',
                    '[class*="icon"]'
                ])
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
                if not title:
                    all_text = await card.text_content()
                    if all_text:
                        lines = all_text.strip().split('\n')
                        title = lines[0] if lines else "Unknown"
                        description = ' '.join(lines[1:3]) if len(lines) > 1 else ""
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ featured —Å–µ—Ä–≤–µ—Ä
                if title:
                    featured_keywords = ['postman', 'byterover', 'bucket', 'allthingsdev', 'mailtrap', 'endgame']
                    is_featured = any(keyword in title.lower() for keyword in featured_keywords)
                    if is_featured:
                        print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º featured —Å–µ—Ä–≤–µ—Ä: {title}")
                        continue
                
                server_data = {
                    "title": title.strip() if title else "Unknown",
                    "description": description.strip() if description else "",
                    "link": link,
                    "icon": icon,
                    "source": "cursor.directory",
                    "selector_used": selector
                }
                
                print(f"üìã –ö–∞—Ä—Ç–æ—á–∫–∞ {i+1}: {server_data['title']}")
                if link:
                    print(f"   üîó –°—Å—ã–ª–∫–∞: {link}")
                servers.append(server_data)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–∫–∏ {i+1}: {e}")
                continue
        
        return servers
    
    async def _extract_text(self, element, selectors: List[str]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        for selector in selectors:
            try:
                elem = await element.query_selector(selector)
                if elem:
                    text = await elem.text_content()
                    if text and text.strip():
                        return text.strip()
            except:
                continue
        return ""
    
    async def _extract_attribute(self, element, selector: str, attribute: str, fallback_selectors: List[str]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        selectors_to_try = [selector] + fallback_selectors
        for sel in selectors_to_try:
            try:
                elem = await element.query_selector(sel)
                if elem:
                    value = await elem.get_attribute(attribute)
                    if value:
                        return value
            except:
                continue
        return ""
    
    async def _extract_link(self, element) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫"""
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏
        link_selectors = [
            'a[href]',
            '[href]',
            '[class*="link"]',
            '[class*="card"] a',
            'a'
        ]
        
        for selector in link_selectors:
            try:
                links = await element.query_selector_all(selector)
                for link in links:
                    href = await link.get_attribute('href')
                    if href:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ MCP —Å–µ—Ä–≤–µ—Ä
                        if '/mcp/' in href or 'cursor.directory' in href:
                            # –î–µ–ª–∞–µ–º —Å—Å—ã–ª–∫—É –∞–±—Å–æ–ª—é—Ç–Ω–æ–π
                            if href.startswith('/'):
                                href = f"https://cursor.directory{href}"
                            elif not href.startswith('http'):
                                href = f"https://cursor.directory/mcp/{href}"
                            return href
            except:
                continue
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É, –∏—â–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é —Å—Å—ã–ª–∫—É
        try:
            parent_link = await element.query_selector('a[href]')
            if parent_link:
                href = await parent_link.get_attribute('href')
                if href:
                    if href.startswith('/'):
                        href = f"https://cursor.directory{href}"
                    elif not href.startswith('http'):
                        href = f"https://cursor.directory/mcp/{href}"
                    return href
        except:
            pass
        
        # –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —Å–∞–º —è–≤–ª—è–µ—Ç—Å—è —Å—Å—ã–ª–∫–æ–π
        try:
            tag_name = await element.evaluate('element => element.tagName.toLowerCase()')
            if tag_name == 'a':
                href = await element.get_attribute('href')
                if href:
                    if href.startswith('/'):
                        href = f"https://cursor.directory{href}"
                    elif not href.startswith('http'):
                        href = f"https://cursor.directory/mcp/{href}"
                    return href
        except:
            pass
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±—É—é —Å—Å—ã–ª–∫—É –≤ —ç–ª–µ–º–µ–Ω—Ç–µ
        try:
            all_links = await element.query_selector_all('a')
            for link in all_links:
                href = await link.get_attribute('href')
                if href and href.strip():
                    # –î–µ–ª–∞–µ–º —Å—Å—ã–ª–∫—É –∞–±—Å–æ–ª—é—Ç–Ω–æ–π
                    if href.startswith('/'):
                        href = f"https://cursor.directory{href}"
                    elif not href.startswith('http'):
                        href = f"https://cursor.directory/mcp/{href}"
                    return href
        except:
            pass
        
        return ""
    
    async def get_featured_servers(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã–¥–µ–ª–µ–Ω–Ω—ã—Ö (featured) MCP —Å–µ—Ä–≤–µ—Ä–æ–≤"""
        print("üåü –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã–¥–µ–ª–µ–Ω–Ω—ã—Ö MCP —Å–µ—Ä–≤–µ—Ä–æ–≤...")
        
        cache_file = self.cache_dir / "featured.json"
        if cache_file.exists():
            print("üìÅ –ù–∞–π–¥–µ–Ω –∫—ç—à featured —Å–µ—Ä–≤–µ—Ä–æ–≤, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                await page.goto(self.base_url, wait_until='networkidle')
                
                print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è featured —Å–µ–∫—Ü–∏–∏
                featured_selectors = [
                    '[data-testid="featured-mcp"]',
                    '.featured',
                    '[class*="featured"]',
                    '[class*="hero"]',
                    '.hero',
                    'section'
                ]
                
                featured_section = None
                for selector in featured_selectors:
                    try:
                        featured_section = await page.query_selector(selector)
                        if featured_section:
                            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ featured —Å–µ–∫—Ü–∏—è —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            break
                    except:
                        continue
                
                if not featured_section:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ featured —Å–µ–∫—Ü–∏—é")
                    return []
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º featured —Å–µ—Ä–≤–µ—Ä—ã
                featured = await self._extract_featured_data(page, featured_section)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(featured, f, ensure_ascii=False, indent=2)
                
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(featured)} featured —Å–µ—Ä–≤–µ—Ä–æ–≤")
                return featured
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ featured —Å–µ—Ä–≤–µ—Ä–æ–≤: {e}")
                return []
            finally:
                await browser.close()
    
    async def _extract_featured_data(self, page, featured_section) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ featured —Å–µ—Ä–≤–µ—Ä–∞—Ö"""
        featured = []
        
        # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –≤ featured —Å–µ–∫—Ü–∏–∏
        cards = await featured_section.query_selector_all('*')
        
        for card in cards:
            try:
                title = await self._extract_text(card, ['h1', 'h2', 'h3', 'strong', 'b'])
                description = await self._extract_text(card, ['p', 'span'])
                link = await self._extract_attribute(card, 'a', 'href', ['a'])
                
                if title and title.strip():
                    featured.append({
                        "title": title.strip(),
                        "description": description.strip() if description else "",
                        "link": link,
                        "source": "cursor.directory",
                        "type": "featured"
                    })
            except Exception as e:
                continue
        
        return featured
    
    def list_cached_queries(self) -> List[str]:
        """–°–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∫—ç—à–µ"""
        queries = []
        for file in self.cache_dir.glob("*.json"):
            if file.name != "featured.json":
                queries.append(file.stem)
        return sorted(queries)
    
    def get_cache_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞"""
        files = list(self.cache_dir.glob("*.json"))
        total_files = len(files)
        total_size = sum(f.stat().st_size for f in files)
        
        file_info = []
        for file in files:
            file_info.append({
                "name": file.name,
                "size": file.stat().st_size
            })
        
        return {
            "cache_dir": str(self.cache_dir),
            "total_files": total_files,
            "total_size": total_size,
            "total_size_mb": round(total_size / 1024 / 1024, 2),
            "files": file_info,
            "cached_queries": self.list_cached_queries()
        }
    def clear_cache(self) -> bool:
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞"""
        try:
            if self.cache_dir.exists():
                for file_path in self.cache_dir.glob("*.json"):
                    file_path.unlink()
                print(f"‚úÖ –ö—ç—à –æ—á–∏—â–µ–Ω: {self.cache_dir}")
                return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞: {e}")
            return False


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    scraper = CursorDirectoryScraper()
    
    if len(sys.argv) < 2:
        print("üìñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python cursor-directory-scraper.py search <query>")
        print("  python cursor-directory-scraper.py featured")
        print("  python cursor-directory-scraper.py cache")
        print("  python cursor-directory-scraper.py stats")
        print("\nüìù –ü—Ä–∏–º–µ—Ä—ã:")
        print("  python cursor-directory-scraper.py search terminal")
        print("  python cursor-directory-scraper.py search java")
        print("  python cursor-directory-scraper.py search database")
        return
    
    command = sys.argv[1]
    
    if command == "search" and len(sys.argv) >= 3:
        query = sys.argv[2]
        servers = await scraper.search_mcp_servers(query)
        
        if servers:
            print(f"\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è '{query}':")
            for i, server in enumerate(servers, 1):
                print(f"\n{i}. {server['title']}")
                print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {server['description']}")
                print(f"   –°—Å—ã–ª–∫–∞: {server['link']}")
                if server.get('featured'):
                    print(f"   üåü Featured —Å–µ—Ä–≤–µ—Ä")
    
    elif command == "featured":
        featured = await scraper.get_featured_servers()
        
        if featured:
            print(f"\nüåü –í—ã–¥–µ–ª–µ–Ω–Ω—ã–µ MCP —Å–µ—Ä–≤–µ—Ä—ã:")
            for i, server in enumerate(featured, 1):
                print(f"\n{i}. {server['title']}")
                print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {server['description']}")
                print(f"   –°—Å—ã–ª–∫–∞: {server['link']}")
    
    elif command == "cache":
        queries = scraper.list_cached_queries()
        if queries:
            print("üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –∫—ç—à–µ:")
            for query in queries:
                print(f"  - {query}")
        else:
            print("üìÅ –ö—ç—à –ø—É—Å—Ç")
    
    elif command == "stats":
        stats = scraper.get_cache_stats()
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞:")
        print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}")
        print(f"  –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stats['total_size_mb']} MB")
        print(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: {len(stats['cached_queries'])}")
        if stats['cached_queries']:
            print("  –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤:")
            for query in stats['cached_queries']:
                print(f"    - {query}")
    
    else:
        print("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: search, featured, cache, stats")

if __name__ == "__main__":
    asyncio.run(main())
